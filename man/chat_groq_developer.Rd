% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/chat-groq.R
\name{chat_groq_developer}
\alias{chat_groq_developer}
\title{Chat with Groq AI Models (Developer Version)}
\usage{
chat_groq_developer(
  system_prompt = NULL,
  base_url = "https://api.groq.com/openai/v1",
  api_key = NULL,
  credentials = NULL,
  model = NULL,
  params = NULL,
  api_args = list(),
  echo = NULL,
  api_headers = character()
)
}
\arguments{
\item{system_prompt}{Optional system prompt to set context for the conversation}

\item{base_url}{Base URL for Groq API. Defaults to Groq's OpenAI-compatible endpoint}

\item{api_key}{Deprecated. Use \code{credentials} instead}

\item{credentials}{API credentials. Defaults to \code{GROQ_API_KEY} environment variable}

\item{model}{Model to use. Defaults to "openai/gpt-oss-20b" which supports
strict structured outputs. Also available: "openai/gpt-oss-120b"}

\item{params}{Optional params object for controlling generation}

\item{api_args}{Additional arguments passed to the API}

\item{echo}{How to display output. One of "none", "text", "all"}

\item{api_headers}{Additional HTTP headers}
}
\value{
A Chat object with methods for:
\itemize{
\item \code{chat()}: Send messages and receive responses
\item \code{chat_structured()}: Extract structured data with type validation
\item Batch processing via ellmer's \code{batch_chat()} and \code{batch_chat_structured()}
\item Parallel processing via ellmer's \code{parallel_chat()} and \code{parallel_chat_structured()}
}
}
\description{
Creates a chat interface for Groq's API with support for structured outputs,
batch processing, and parallel execution. This developer version extends
ProviderOpenAI to inherit full batch support while adding Groq-specific
schema formatting (additionalProperties: false).
}
\section{Structured Outputs}{

Groq supports strict JSON schema validation with guaranteed compliance when using
compatible models. All objects must have \code{additionalProperties: false} and all
fields must be required (or use union with null for optional fields).
}

\section{Batch Processing}{

Groq's batch API offers 50\% cost discount and no rate limit impact. Batch jobs
are processed asynchronously with completion windows from 24 hours to 7 days.
Use \code{batch_chat()} or \code{batch_chat_structured()} from ellmer to submit batches.
}

\section{Models}{

For strict structured output support, use:
\itemize{
\item \code{"openai/gpt-oss-20b"} (default, recommended)
\item \code{"openai/gpt-oss-120b"}
}

Other models support best-effort JSON output but may not guarantee schema compliance.
}

\examples{
\dontrun{
# Basic chat
chat <- chat_groq_developer()
chat$chat("What is the capital of France?")

# Structured output
type_person <- type_object(
  name = type_string(),
  age = type_integer(),
  city = type_string()
)
result <- chat$chat_structured(
  "John is 30 years old and lives in NYC",
  type = type_person
)

# Batch processing (requires ellmer's batch functions)
library(ellmer)
chat <- chat_groq_developer()
results <- batch_chat(
  chat,
  prompts = c("Question 1?", "Question 2?", "Question 3?"),
  wait = FALSE  # Async - check back later
)

# Parallel processing
results <- parallel_chat(
  chat,
  prompts = c("Question 1?", "Question 2?", "Question 3?")
)
}

}
\seealso{
\itemize{
\item \code{\link[ellmer:batch_chat]{ellmer::batch_chat()}} for batch processing
\item \code{\link[ellmer:parallel_chat]{ellmer::parallel_chat()}} for parallel processing
\item \code{\link[ellmer:type_boolean]{ellmer::type_object()}}, \code{\link[ellmer:type_boolean]{ellmer::type_array()}} for defining types
}
}
