[{"path":"https://xmarquez.github.io/groqDeveloper/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Xavier Marquez. Author, maintainer.","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Marquez X (2026). groqDeveloper: Groq AI Provider Structured Output Batch Support. R package version 0.1.0, https://github.com/xmarquez/groqDeveloper.","code":"@Manual{,   title = {groqDeveloper: Groq AI Provider with Structured Output and Batch Support},   author = {Xavier Marquez},   year = {2026},   note = {R package version 0.1.0},   url = {https://github.com/xmarquez/groqDeveloper}, }"},{"path":"https://xmarquez.github.io/groqDeveloper/index.html","id":"groqdeveloper","dir":"","previous_headings":"","what":"Groq AI Provider with Structured Output and Batch Support","title":"Groq AI Provider with Structured Output and Batch Support","text":"package extends ellmer package’s ProviderOpenAICompatible (Chat Completions format) adding Groq-specific enhancements, particular structured outputs, batch processing, models_groq() function. mask ellmer::chat_groq(), creates Chat object using chat_groq_developer(). need paid developer account use batch processing features. package otherwise fully integrated ellmer – works batch_chat(), parallel_chat(), batch_chat_structured(), etc.","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Groq AI Provider with Structured Output and Batch Support","text":"can install development version groqDeveloper GitHub:","code":"# install.packages(\"devtools\") devtools::install_github(\"xmarquez/groqDeveloper\")"},{"path":"https://xmarquez.github.io/groqDeveloper/index.html","id":"setup","dir":"","previous_headings":"","what":"Setup","title":"Groq AI Provider with Structured Output and Batch Support","text":"need set Groq API key use package. add key .Renviron file.","code":"Sys.setenv(GROQ_API_KEY = \"your-api-key-here\")"},{"path":[]},{"path":"https://xmarquez.github.io/groqDeveloper/index.html","id":"basic-chat","dir":"","previous_headings":"Examples","what":"Basic chat","title":"Groq AI Provider with Structured Output and Batch Support","text":"","code":"library(groqDeveloper)  chat <- chat_groq_developer(model = \"openai/gpt-oss-20b\") chat$chat(\"What is the capital of France?\")"},{"path":"https://xmarquez.github.io/groqDeveloper/index.html","id":"structured-output","dir":"","previous_headings":"Examples","what":"Structured output","title":"Groq AI Provider with Structured Output and Batch Support","text":"","code":"# Define the structure type_person <- ellmer::type_object(   name = ellmer::type_string(),   age = ellmer::type_integer(),   city = ellmer::type_string() )  # Extract structured data result <- chat$chat_structured(   \"John is 30 years old and lives in New York City\",   type = type_person )  # Result is a list matching the schema str(result)"},{"path":"https://xmarquez.github.io/groqDeveloper/index.html","id":"batch-processing","dir":"","previous_headings":"Examples","what":"Batch processing","title":"Groq AI Provider with Structured Output and Batch Support","text":"Process multiple requests cost savings using Groq’s batch API. Groq batch API typically blazingly fast; though completion guaranteed least 24 hours, requests 500 prompts finish seconds.","code":"prompts <- list(   \"What is 2+2?\",   \"What is the capital of France?\",   \"Who wrote Romeo and Juliet?\" )  # Submit batch job (returns NULL if wait = FALSE and not complete) results_file <- tempfile(fileext = \".json\")  # This is typically very fast! chats <- batch_chat(   chat,   prompts = prompts,   path = results_file )  chats"},{"path":"https://xmarquez.github.io/groqDeveloper/index.html","id":"batch-structured-output","dir":"","previous_headings":"Examples","what":"Batch structured output","title":"Groq AI Provider with Structured Output and Batch Support","text":"","code":"type_answer <- ellmer::type_object(   question = ellmer::type_string(),   answer = ellmer::type_string() )  results_file <- tempfile(fileext = \".json\")  data <- batch_chat_structured(   chat,   prompts = list(\"What is 2+2?\", \"What is the capital of France?\"),   path = results_file,   type = type_answer )  data"},{"path":"https://xmarquez.github.io/groqDeveloper/index.html","id":"parallel-processing","dir":"","previous_headings":"Examples","what":"Parallel processing","title":"Groq AI Provider with Structured Output and Batch Support","text":"Process multiple prompts concurrently (synchronous):","code":"results <- parallel_chat(   chat,   prompts = list(     \"Tell me about Paris\",     \"Tell me about London\",     \"Tell me about Tokyo\"   ) )  results"},{"path":"https://xmarquez.github.io/groqDeveloper/index.html","id":"supported-models","dir":"","previous_headings":"","what":"Supported models","title":"Groq AI Provider with Structured Output and Batch Support","text":"strict structured outputs, Groq supports following models 2 January 2025:","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/index.html","id":"groq-structured-outputs---supported-models","dir":"","previous_headings":"","what":"Groq Structured Outputs - Supported Models","title":"Groq AI Provider with Structured Output and Batch Support","text":"following models support strict: true, uses constrained decoding guarantee schema-compliant output: following models support Structured Outputs strict: false (default), attempts schema compliance may occasionally error: models offered Groq can use JSON object mode generate valid JSON, without schema compliance. can use JSON object mode passing param response_format setting list(\"type\" = \"json_object\"), decoding text response using jsonlite::from_json() Streaming tool use currently supported Structured Outputs Groq.","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/index.html","id":"batch-processing---supported-models","dir":"","previous_headings":"","what":"Batch processing - Supported Models","title":"Groq AI Provider with Structured Output and Batch Support","text":"batch processing, Groq supports following models 2 January 2025: Pricing 50% cost discount compared synchronous API pricing. batch discount stack prompt caching discounts. batch tokens billed 50% batch rate regardless cache status. package mostly coded Claude Code (Opus 4.5), though everything reviewed (Xavier Marquez), including live tests. ’ve used workloads thousands prompts time.","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Groq AI Provider with Structured Output and Batch Support","text":"MIT","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/ProviderGroqDeveloper.html","id":null,"dir":"Reference","previous_headings":"","what":"Groq Developer Provider Class — ProviderGroqDeveloper","title":"Groq Developer Provider Class — ProviderGroqDeveloper","text":"S7 class extends ProviderOpenAICompatible provide Groq-specific functionality. Inherits capabilities ProviderOpenAICompatible (uses Chat Completions API format) ensuring proper schema formatting Groq's strict JSON validation.","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/ProviderGroqDeveloper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Groq Developer Provider Class — ProviderGroqDeveloper","text":"","code":"ProviderGroqDeveloper(   name = stop(\"Required\"),   model = stop(\"Required\"),   base_url = stop(\"Required\"),   params = list(),   extra_args = list(),   extra_headers = character(0),   credentials = function() NULL )"},{"path":"https://xmarquez.github.io/groqDeveloper/reference/ProviderGroqDeveloper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Groq Developer Provider Class — ProviderGroqDeveloper","text":"name Provider name model Model identifier (e.g., \"openai/gpt-oss-20b\") base_url API base URL params Parameters list generation control extra_args Additional API arguments extra_headers Additional HTTP headers credentials API credentials (function string)","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/ProviderGroqDeveloper.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Groq Developer Provider Class — ProviderGroqDeveloper","text":"class also implements batch processing support via Groq's Batch API, offers 50% cost discount compared synchronous API calls. Users typically use chat_groq_developer() instead calling constructor directly. class exported advanced use cases.","code":""},{"path":[]},{"path":"https://xmarquez.github.io/groqDeveloper/reference/chat_groq_developer.html","id":null,"dir":"Reference","previous_headings":"","what":"Chat with Groq AI Models (Developer Version) — chat_groq_developer","title":"Chat with Groq AI Models (Developer Version) — chat_groq_developer","text":"Creates chat interface Groq's API support structured outputs, batch processing, parallel execution. developer version extends ellmer's ProviderOpenAICompatible inherit full batch support adding Groq-specific schema formatting (additionalProperties: false). Sign https://groq.com. Built top ellmer's ProviderOpenAICompatible class.","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/chat_groq_developer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chat with Groq AI Models (Developer Version) — chat_groq_developer","text":"","code":"chat_groq_developer(   system_prompt = NULL,   base_url = \"https://api.groq.com/openai/v1\",   api_key = NULL,   credentials = NULL,   model = NULL,   params = NULL,   api_args = list(),   echo = NULL,   api_headers = character() )"},{"path":"https://xmarquez.github.io/groqDeveloper/reference/chat_groq_developer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Chat with Groq AI Models (Developer Version) — chat_groq_developer","text":"system_prompt system prompt set behavior assistant. base_url Base URL Groq API. api_key Use credentials instead. credentials Override default credentials. generally need argument; instead set GROQ_API_KEY environment variable. best place set .Renviron, can easily edit calling usethis::edit_r_environ(). need additional control, argument takes zero-argument function returns either string (API key), named list (added additional headers every request). model model use chat (defaults \"openai/gpt-oss-20b\"). regularly update default, strongly recommend explicitly specifying model anything casual use. Use models_groq() see options. params Common model parameters, usually created ellmer::params(). api_args Additional arguments passed API. echo Whether echo conversation console. One : \"none\": output \"output\": Echo assistant responses \"\": Echo messages Defaults \"output\" interactive sessions, \"none\" otherwise. api_headers Additional HTTP headers.","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/chat_groq_developer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Chat with Groq AI Models (Developer Version) — chat_groq_developer","text":"ellmer::Chat object methods : $chat(): Send messages receive responses $chat_structured(): Extract structured data type validation Batch processing via batch_chat() batch_chat_structured() Parallel processing via parallel_chat() parallel_chat_structured()","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/chat_groq_developer.html","id":"structured-outputs","dir":"Reference","previous_headings":"","what":"Structured Outputs","title":"Chat with Groq AI Models (Developer Version) — chat_groq_developer","text":"Groq supports strict JSON schema validation guaranteed compliance using compatible models. See https://console.groq.com/docs/structured-outputs details.","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/chat_groq_developer.html","id":"batch-processing","dir":"Reference","previous_headings":"","what":"Batch Processing","title":"Chat with Groq AI Models (Developer Version) — chat_groq_developer","text":"Groq's batch API offers 50% cost discount rate limit impact. Batch jobs processed asynchronously completion windows 24 hours 7 days. Use batch_chat() batch_chat_structured() submit batches. See https://console.groq.com/docs/batch details.","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/chat_groq_developer.html","id":"models","dir":"Reference","previous_headings":"","what":"Models","title":"Chat with Groq AI Models (Developer Version) — chat_groq_developer","text":"strict structured output support, use: \"openai/gpt-oss-20b\" (default) \"openai/gpt-oss-120b\" models support best-effort JSON output may guarantee schema compliance.","code":""},{"path":[]},{"path":"https://xmarquez.github.io/groqDeveloper/reference/chat_groq_developer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Chat with Groq AI Models (Developer Version) — chat_groq_developer","text":"","code":"if (FALSE) { # \\dontrun{ # Basic chat chat <- chat_groq_developer() chat$chat(\"What is the capital of France?\")  # Structured output type_person <- ellmer::type_object(   name = ellmer::type_string(),   age = ellmer::type_integer(),   city = ellmer::type_string() ) result <- chat$chat_structured(   \"John is 30 years old and lives in NYC\",   type = type_person )  # Batch processing results <- batch_chat(   chat,   prompts = c(\"Question 1?\", \"Question 2?\", \"Question 3?\") )  # Parallel processing results <- parallel_chat(   chat,   prompts = c(\"Question 1?\", \"Question 2?\", \"Question 3?\") ) } # }"},{"path":"https://xmarquez.github.io/groqDeveloper/reference/groqDeveloper-package.html","id":null,"dir":"Reference","previous_headings":"","what":"groqDeveloper: Groq AI Provider with Structured Output and Batch Support — groqDeveloper-package","title":"groqDeveloper: Groq AI Provider with Structured Output and Batch Support — groqDeveloper-package","text":"Provides Groq AI provider ellmer package full support structured outputs, batch processing, parallel execution. Extends ProviderOpenAICompatible leverage Groq's OpenAI-compatible Chat Completions API strict JSON schema validation structured outputs.","code":""},{"path":[]},{"path":"https://xmarquez.github.io/groqDeveloper/reference/groqDeveloper-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"groqDeveloper: Groq AI Provider with Structured Output and Batch Support — groqDeveloper-package","text":"Maintainer: Xavier Marquez marquez.x@gmail.com","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/groq_key.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Groq API key — groq_key","title":"Get Groq API key — groq_key","text":"Get Groq API key","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/groq_key.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Groq API key — groq_key","text":"","code":"groq_key()"},{"path":"https://xmarquez.github.io/groqDeveloper/reference/is_snapshot.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if running in snapshot mode — is_snapshot","title":"Check if running in snapshot mode — is_snapshot","text":"Check running snapshot mode","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/is_snapshot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if running in snapshot mode — is_snapshot","text":"","code":"is_snapshot()"},{"path":"https://xmarquez.github.io/groqDeveloper/reference/is_testing.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if running in test mode — is_testing","title":"Check if running in test mode — is_testing","text":"Check running test mode","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/is_testing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if running in test mode — is_testing","text":"","code":"is_testing()"},{"path":"https://xmarquez.github.io/groqDeveloper/reference/key_get.html","id":null,"dir":"Reference","previous_headings":"","what":"Get API key from environment variable — key_get","title":"Get API key from environment variable — key_get","text":"Get API key environment variable","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/key_get.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get API key from environment variable — key_get","text":"","code":"key_get(name, error_call = rlang::caller_env())"},{"path":"https://xmarquez.github.io/groqDeveloper/reference/models_groq.html","id":null,"dir":"Reference","previous_headings":"","what":"List Available Groq Models — models_groq","title":"List Available Groq Models — models_groq","text":"Retrieves list available models Groq API. Returns model metadata including context window size active status.","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/models_groq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Available Groq Models — models_groq","text":"","code":"models_groq(   base_url = \"https://api.groq.com/openai/v1\",   api_key = NULL,   credentials = NULL )"},{"path":"https://xmarquez.github.io/groqDeveloper/reference/models_groq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List Available Groq Models — models_groq","text":"base_url Base URL Groq API. api_key Use credentials instead. credentials Override default credentials. generally need argument; instead set GROQ_API_KEY environment variable.","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/models_groq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List Available Groq Models — models_groq","text":"data frame columns: id Model identifier (e.g., \"llama-3.3-70b-versatile\") created_at Date model created owned_by Organization owns/provides model context_window Maximum context window size tokens active Whether model currently active/available","code":""},{"path":[]},{"path":"https://xmarquez.github.io/groqDeveloper/reference/models_groq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List Available Groq Models — models_groq","text":"","code":"if (FALSE) { # \\dontrun{ # List all available models models <- models_groq() print(models)  # Filter for active models with large context windows large_context <- models[models$context_window >= 32768 & models$active, ] } # }"},{"path":"https://xmarquez.github.io/groqDeveloper/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. ellmer batch_chat, batch_chat_completed, batch_chat_structured, batch_chat_text, parallel_chat, parallel_chat_structured, parallel_chat_text","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/set_default.html","id":null,"dir":"Reference","previous_headings":"","what":"Set default value with informative message — set_default","title":"Set default value with informative message — set_default","text":"Set default value informative message","code":""},{"path":"https://xmarquez.github.io/groqDeveloper/reference/set_default.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set default value with informative message — set_default","text":"","code":"set_default(value, default, arg = rlang::caller_arg(value))"}]
